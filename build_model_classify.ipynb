{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----install stuff\n",
    "!pip install mlxtend\n",
    "!pip install -U imbalanced-learn\n",
    "!python ../../software/python-glmnet/setup.py\n",
    "!conda install -c conda-forge tensorflow\n",
    "!conda install -c conda-forge keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs_general import *\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from funcs_general import *\n",
    "\n",
    "# ---------------- import\n",
    "from sklearn import base\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import auc, roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# models\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#from glmnet import LogitNet\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE  \n",
    "from imblearn.pipeline import Pipeline as ImbPipe\n",
    "\n",
    "#from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def PowLog(X):\n",
    "    X=pd.DataFrame(X)\n",
    "    Xpow=X.apply(lambda row: np.power(row,2), axis=1)\n",
    "    X = pd.concat([X, Xpow], axis=1)\n",
    "    return X\n",
    "    \n",
    "FeaturePowLog = FunctionTransformer(PowLog)\n",
    "\n",
    "\n",
    "#--------calculate fees\n",
    "def get_fees(returns,FEE_BUY,FEE_SELL):\n",
    "    returns=np.array(returns)\n",
    "    v=np.repeat(0.0,len(returns))\n",
    "    for i in np.arange(len(returns)):\n",
    "        if returns[i] != 1: v[i] = (returns[i] * FEE_BUY + returns[i] * FEE_SELL)\n",
    "    return v\n",
    "\n",
    "#-----calculate ROI depending on cutoff value\n",
    "def get_ROI(test,y_pred,strategy=\"reinvest\"):\n",
    "    \n",
    "    \n",
    "    test['y_pred'] = y_pred\n",
    "    test['return'] = 1.0\n",
    "    test.loc[test.y_pred == 1,'return']  = test.loc[test.y_pred == 1,'target'] + 1\n",
    "    \n",
    "    test['lags'] = np.concatenate((np.array([0.0]),np.diff(np.array(test.timstamp), n=1, axis=-1)), axis=0)\n",
    "    test['trade'] = test['y_pred']\n",
    "    \n",
    "    if (SKIP_TRADE > 0) : \n",
    "        test['trade']  = skip_trades(test['trade'].values,test['lags'].values,SKIP_TRADE)\n",
    "        test.loc[test.trade == 0,'return']  = 1\n",
    "        \n",
    "    if (strategy==\"reinvest\"):\n",
    "        test['fees'] = get_fees(test['return'],FEE_BUY,FEE_SELL)  \n",
    "        test['return_cum'] = np.cumprod(np.array(test['return']) - np.array(test['fees']) )\n",
    "        #test['return_cum']=test['return_cum'] - test['fees'] \n",
    "        \n",
    "    if (strategy==\"fixed\") : \n",
    "        test['return_cum'] = 1 + np.cumsum(test['return'].values - 1)\n",
    "        test['fees'] = np.where(test['return'] != 1,(FEE_BUY+FEE_SELL),0)\n",
    "    \n",
    "    ROI = float(test['return_cum'].tail(1))\n",
    "    fees = sum(test['fees'])\n",
    "    \n",
    "    trades = sum(test['trade'])\n",
    "    days = (float(test.timstamp.tail(1)) - float(test.timstamp.head(1))) / 3600 / 24\n",
    "    \n",
    "    out=pd.DataFrame({'ROI': [ROI], 'ROI_bench' : test.mid.values[-1:] / test.mid.values[0],\n",
    "                      'ROI_day' : [ROI/days],\n",
    "                      'trades' : [trades], 'days' : [days], 'strategy' : [strategy] })\n",
    "    return  {'kpis' : out, 'data' : test}\n",
    "\n",
    "\n",
    "#------once traded, wait until previous trade was completed. Skip test cases until gap > time_future\n",
    "def skip_trades(trade,lags,seconds):\n",
    "  \n",
    "    counter=[0.0]\n",
    "    counting = False\n",
    "\n",
    "    for i in np.arange(len(trade)):\n",
    "\n",
    "        # set value to 1\n",
    "        if counting == True:\n",
    "            trade[i] = 0\n",
    "            counter.append(lags[i])\n",
    "\n",
    "        # ON\n",
    "        if trade[i] ==1: counting = True\n",
    "\n",
    "        # OFF\n",
    "        if sum(counter) > seconds:\n",
    "            counter=[0.0]\n",
    "            counting = False\n",
    "\n",
    "    return trade\n",
    "\n",
    "#-----optimization: find best cutoff for max ROI\n",
    "from scipy.optimize import minimize_scalar\n",
    "\n",
    "def find_opt_ROI(cutoff):\n",
    "    y_pred=np.where(test.y_pred_prob >= cutoff, 1,0) \n",
    "    obj_ROI = get_ROI(test,y_pred,strategy=\"reinvest\")\n",
    "    roi=float(obj_ROI['kpis']['ROI'].values)\n",
    "    if (roi < 0) : roi = 0.0001\n",
    "    return float(-roi)\n",
    "\n",
    "\n",
    "import itertools\n",
    "def expandgrid(*itrs):\n",
    "   product = list(itertools.product(*itrs))\n",
    "   return {'Var{}'.format(i+1):[x[i] for x in product] for i in range(len(itrs))}\n",
    "\n",
    "def eval_model(test,cutoff):\n",
    "\n",
    "    if TYPE == \"classify\": bounds=(0,1)\n",
    "    if TYPE == \"regression\": bounds=(0,0.015)\n",
    "    \n",
    "    if cutoff < 0:\n",
    "        best_cutoff=minimize_scalar(find_opt_ROI,bounds=bounds, method='bounded',options={'maxiter' : 500000})\n",
    "        cutoff=best_cutoff['x']\n",
    "    \n",
    "    y_pred=np.where(test.y_pred_prob.values >= cutoff, 1,0) \n",
    "    if hasattr(MODEL,'scoring'): model_scoring = MODEL.scoring\n",
    "    else: model_scoring = None\n",
    "    \n",
    "    \n",
    "    obj_ROI = get_ROI(test,y_pred,strategy=\"reinvest\")\n",
    "    obj_ROI['kpis']['max_trades'] = confusion_matrix(test.target_cat, y_pred)[1,0]\n",
    "    obj_ROI['kpis']['days_trading'] = len(set([str(datetime.fromtimestamp(e).date()) for e in test.iloc[np.where(y_pred == 1)[0],:]['timstamp'].values]))\n",
    "    obj_ROI['kpis']['cutoff'] = cutoff\n",
    "    obj_ROI['kpis']['precision'] = precision_score(test.target_cat,y_pred,pos_label=1)\n",
    "    obj_ROI['kpis']['DIRECTION'] = DIRECTION\n",
    "    obj_ROI['kpis']['THRES_PROF'] = THRES_PROF\n",
    "    obj_ROI['kpis']['TARGET_TIME']=TARGET_TIME\n",
    "    obj_ROI['kpis']['TRAIN_THRES']=TRAIN_THRES\n",
    "    obj_ROI['kpis']['N_TRAIN']=N_TRAIN\n",
    "    obj_ROI['kpis']['MODEL_SCORER'] = model_scoring\n",
    "    obj_ROI['kpis']['TYPE']=TYPE\n",
    "    o=obj_ROI['data']\n",
    "    #o.loc[o['trade']==1,o.columns[-9:]]\n",
    "    return obj_ROI\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#-----------precision custom scorer\n",
    "def custom_precision(y_true,probas_pred): \n",
    "    pos_label=1\n",
    "    precision, recall, _ = precision_recall_curve(y_true,probas_pred,pos_label=pos_label)\n",
    "    cut = np.where(precision >= 0.5)[0]\n",
    "    if len(cut) <= 1: area = 0\n",
    "    else: area = auc(recall[cut], precision[cut])\n",
    "    area = auc(recall, precision)\n",
    "    return area\n",
    "\n",
    "def custom_precision_wrapper(y_true,probas_pred):\n",
    "    return custom_precision(y_true,probas_pred[:, 1])\n",
    "\n",
    "#------MAXIMIZE: bigger is better!\n",
    "score_custom_precision = make_scorer(custom_precision_wrapper,greater_is_better=True,needs_proba=True)\n",
    "\n",
    "#------------custom regression scorers\n",
    "\n",
    "def custom_score_regression1(y_true,y_pred): \n",
    "    \n",
    "    y_pred=np.array(y_pred)\n",
    "    y_true=np.array(y_true)\n",
    "    \n",
    "    #  money \n",
    "    i_in = np.where(y_true >= THRES_PROF)[0]\n",
    "    i_out = np.where(y_true < THRES_PROF)[0]\n",
    "    \n",
    "    \n",
    "    # >= 0.0042 in the money\n",
    "    list_i = []\n",
    "    for i in i_in:\n",
    "        if y_pred[i] >= y_true[i]: list_i.append( (y_pred[i]- y_true[i]) * 1 )\n",
    "        if y_pred[i] < y_true[i]: list_i.append( (y_true[i]- y_pred[i] ) * 0 )\n",
    "    \n",
    "    # < 0.0042 out of money \n",
    "    for i in i_out:\n",
    "        if y_pred[i] >= THRES_PROF: list_i.append( abs(y_pred[i] - y_true[i]) * 10 )\n",
    "        if y_pred[i] < THRES_PROF: list_i.append(0)\n",
    "    \n",
    "    out = sum(np.array(list_i)) / (len(i_in))\n",
    "    print('in, out, score: ',len(i_in), len(i_out) ,out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def custom_score_regression2(y_true,y_pred): \n",
    "    \n",
    "    \n",
    "    THRES=TRAIN_THRES\n",
    "    \n",
    "    y_pred=np.array(y_pred)\n",
    "    y_true=np.array(y_true)\n",
    "    \n",
    "    # punish false positives\n",
    "    i_wrong = np.where((y_pred > THRES) & (y_true <= THRES))[0]\n",
    "    wrong = y_true[i_wrong] - THRES\n",
    "    wrong = abs(wrong * 3)\n",
    "    loss1 = np.sum(wrong)\n",
    "    av_loss1 = loss1/len(wrong)\n",
    "    \n",
    "    # punish false negatives\n",
    "    i_missed = np.where((y_pred < THRES) & (y_true >= THRES))[0]\n",
    "    missed = y_true[i_missed] - THRES\n",
    "    missed = abs(missed)\n",
    "    loss2 = np.sum(missed * 2)\n",
    "    av_loss2 = loss2/len(missed)\n",
    "    \n",
    "    out=np.nansum([av_loss1,av_loss2])\n",
    "    \n",
    "    print(len(wrong), len(missed), out)\n",
    "    return out\n",
    "\n",
    "\n",
    "#------MINIMIZE: smaller is better!\n",
    "score_custom_regression = make_scorer(custom_score_regression2,greater_is_better=False)\n",
    "\n",
    "#custom_score_regression(test.target.values,test.y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(X):\n",
    "    # feature transformation: take sqrt of count data\n",
    "    for e in X.filter(regex=('count$')).columns: X[e] = np.sqrt(X[e] )\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------classification pipe\n",
    "sm=SMOTEENN(random_state=1,ratio='minority')\n",
    "sm=SMOTE(random_state=1,ratio='minority')\n",
    "#clf2=LogitNet(fit_intercept=True,alpha=0,n_splits=3,n_jobs=1, scoring=score_custom_precision)\n",
    "#fsel=RFECV(clf1,step=1, cv=TimeSeriesSplit(n_splits=2), scoring=\"log_loss\", verbose=0, n_jobs=1)\n",
    "pipe=ImbPipe([\n",
    "            ('ft', FunctionTransformer(transform_features,validate=False)),\n",
    "            ('rs', StandardScaler()), \n",
    "            ('pca',PCA()),\n",
    "            #('fs', fsel), \n",
    "            ('sm', sm), \n",
    "            ('clf1',LogisticRegression(fit_intercept=True,C=0.001))\n",
    "            ])\n",
    "params = {\n",
    "          'clf1__C': [0.0001,0.0005,0.001,0.003,0.005,0.01,0.05],\n",
    "            'clf1__penalty': ['l1']\n",
    "         }\n",
    "grid1 = GridSearchCV(estimator=pipe,refit=True,param_grid=params,n_jobs=16,verbose=0,\n",
    "                    cv=TimeSeriesSplit(n_splits=2),\n",
    "                    scoring=\"log_loss\")\n",
    "grid2 = GridSearchCV(estimator=pipe,refit=True,param_grid=params,n_jobs=16,verbose=0,\n",
    "                    cv=TimeSeriesSplit(n_splits=2),\n",
    "                    scoring=score_custom_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting function rolling window timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def backtesting(d):\n",
    "    gc.collect()\n",
    "    cv=TimeSeriesSplit(n_splits=BACKTEST_SPLITS,max_train_size=N_TRAIN_MIN)\n",
    "    test_list = []\n",
    "    best_params=[]\n",
    "    for i in cv.split(d):\n",
    "        \n",
    "        i_train, i_test = i\n",
    "        print(len(i_train))\n",
    "        \n",
    "        if (len(i_train) >= N_TRAIN_MIN):\n",
    "            \n",
    "            # Set training N\n",
    "            i_train = i_train[-N_TRAIN:] \n",
    "            X=d.iloc[i_train,:]\n",
    "            X = X[(X.target >= TRAIN_THRES) | (X.target < THRES_PROF) ] \n",
    "            \n",
    "            target_freq = np.sum(X.target_cat) / N_TRAIN * 2\n",
    "            #new=d.iloc[0:i_train[0],:]\n",
    "            #new=new[(new.target >= TRAIN_THRES)]\n",
    "            #X = new.append(X)\n",
    "            \n",
    "            print(i_test[0],i_test[-1:],sum(X.target_cat),sum(X.target_cat)/X.shape[0])\n",
    "            \n",
    "            if TYPE == \"classify\": y= X.target_cat    \n",
    "            if TYPE == \"regression\": y= X.target\n",
    "                \n",
    "            X=X.loc[:,FEATURES]\n",
    "            test=d.iloc[i[1],:]\n",
    "\n",
    "            MODEL.fit(X,y)\n",
    "\n",
    "            if (hasattr(MODEL,'best_estimator_')) == True: PREDICTOR = MODEL.best_estimator_\n",
    "            if (hasattr(MODEL,'best_estimator_')) == False: PREDICTOR = MODEL\n",
    "\n",
    "            if TYPE == \"classify\":\n",
    "                y_pred_prob2=PREDICTOR.predict_proba(test.loc[:,FEATURES])\n",
    "                test['y_pred_prob'] = np.asarray([p[1] for p in y_pred_prob2 ])\n",
    "\n",
    "            if TYPE == \"regression\":\n",
    "                test['y_pred_prob'] = PREDICTOR.predict(test.loc[:,FEATURES])\n",
    "\n",
    "            if (hasattr(MODEL,'best_estimator_')):\n",
    "                best_params.append(MODEL.best_params_)\n",
    "                print(MODEL.best_params_, MODEL.best_score_)\n",
    "\n",
    "            test_list.append(test)\n",
    "\n",
    "    test = pd.concat(test_list)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    target = 'mid' + str(TARGET_TIME)\n",
    "    d=dr.dropna(subset=[target])\n",
    "    d['target'] = d[target]\n",
    "    if DIRECTION == \"short\": d['target'] = -1 * d['target'] \n",
    "    d['target_cat'] = np.where(d['target'] >= THRES_PROF, 1,0)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -------load data\n",
    "dr=pd.read_csv(\"training_data/bitfinex_btcusd.csv.gz\")\n",
    "DAYS=ma.ceil((dr.timstamp[-1:] - dr.timstamp[1])/3600/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463165, 35)\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "dr.columns\n",
    "print(dr.shape)\n",
    "print(DAYS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute force test thresholds for data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "runner=pd.DataFrame(expandgrid(\n",
    "                ['long'],\n",
    "                [0.004081],\n",
    "                [pipe],\n",
    "                [100000,150000],\n",
    "                [0.0042,0.006,0.007,0.008,0.009,0.01,0.012,0.014,0.016,0.018,0.02,0.022,0.024,0.026],\n",
    "                #[0.013,0.014,0.015],\n",
    "                [300,60,900]\n",
    "))\n",
    "runner.columns = ['DIRECTION','THRES_PROF','MODEL','N_TRAIN','TRAIN_THRES','TARGET_TIME']\n",
    "\n",
    "print('brute force runs: ' + str(len(runner)))\n",
    "\n",
    "for i in np.arange(0,runner.shape[0]):\n",
    "    print('#----------------' + str(i))\n",
    "    with open('log_backtest.txt', 'a') as f: f.write('#----------------' + str(i) + ' of ' +str(runner.shape[0]) )\n",
    "    DIRECTION = runner.loc[i,'DIRECTION']\n",
    "    THRES_PROF = runner.loc[i,'THRES_PROF']\n",
    "    TARGET_TIME = runner.loc[i,'TARGET_TIME']\n",
    "    TRAIN_THRES = runner.loc[i,'TRAIN_THRES']\n",
    "    N_TRAIN = runner.loc[i,'N_TRAIN']\n",
    "    N_TRAIN_MIN = 150000\n",
    "    SKIP_TRADE=TARGET_TIME\n",
    "    FEE_BUY=0.002\n",
    "    FEE_SELL=0.002\n",
    "    TYPE=\"classify\"\n",
    "    TRAIN_STRATEGY = \"NONE\"\n",
    "    MODEL=runner.loc[i,'MODEL']\n",
    "    BACKTEST_SPLITS=10\n",
    "    d=prep_data(dr)\n",
    "    FEATURES = d.filter(regex=('width$|^(imba)|^(adj)|^(tr)|^(t[0-9])|^(agg)|(mid$)')).columns\n",
    "    gc.collect()\n",
    "    try:\n",
    "        test=backtesting(d)\n",
    "        r=eval_model(test,-999)['kpis']\n",
    "        result.append(r)\n",
    "        pd.concat(result).sort_values(\"ROI\",ascending=False).to_csv('models_brute.csv')\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "        with open('log_backtest.txt', 'a') as f: f.write('#----------------' + str(i) + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(result).sort_values('ROI',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22058\n",
      "44098\n",
      "66138\n",
      "88178\n",
      "110218\n",
      "132258\n",
      "150000\n",
      "154298 [176337] 4321 0.0288205005069\n",
      "150000\n",
      "176338 [198377] 3741 0.0249521433764\n",
      "150000\n",
      "198378 [220417] 4422 0.0294957310566\n",
      "150000\n",
      "220418 [242457] 4608 0.0307374178701\n",
      "150000\n",
      "242458 [264497] 5496 0.0366602853579\n",
      "150000\n",
      "264498 [286537] 7280 0.0485627947622\n",
      "150000\n",
      "286538 [308577] 8737 0.0582898011195\n",
      "150000\n",
      "308578 [330617] 9434 0.0629483081892\n",
      "150000\n",
      "330618 [352657] 9698 0.064710710163\n",
      "150000\n",
      "352658 [374697] 8635 0.0576131412673\n",
      "150000\n",
      "374698 [396737] 8086 0.0539476668935\n",
      "150000\n",
      "396738 [418777] 10803 0.0720714109398\n",
      "150000\n",
      "418778 [440817] 13777 0.0919011947089\n"
     ]
    }
   ],
   "source": [
    "#--------------BACKTESTING\n",
    "DIRECTION = 'long'\n",
    "THRES_PROF = 0.004081\n",
    "TARGET_TIME = 120\n",
    "TRAIN_THRES=0.0041\n",
    "N_TRAIN = 150000\n",
    "N_TRAIN_MIN = 150000\n",
    "N_WINDOW_MIN = 150000\n",
    "SKIP_TRADE=TARGET_TIME\n",
    "TYPE=\"classify\"\n",
    "TRAIN_STRATEGY = \"NONE\"\n",
    "MODEL=pipe\n",
    "BACKTEST_SPLITS=19\n",
    "d=prep_data(dr)\n",
    "FEATURES = d.filter(regex=('width$|^(imba)|^(adj)|^(tr)|^(t[0-9])|^(agg)|(mid$)')).columns\n",
    "test=backtesting(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ROI  ROI_bench   ROI_day       days  strategy  trades  max_trades  \\\n",
      "0  1.175559   0.656227  0.099043  11.869212  reinvest     116       23321   \n",
      "\n",
      "   days_trading  cutoff  precision DIRECTION  THRES_PROF  TARGET_TIME  \\\n",
      "0             5    0.99    0.43151      long    0.004081          120   \n",
      "\n",
      "   TRAIN_THRES  N_TRAIN MODEL_SCORER      TYPE  \n",
      "0       0.0041   150000         None  classify  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAHvCAYAAAD6ogF/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3Xt01PWd//HX3DJMQkIGk4CAYkEJ\nCeESI9UiJAaKegCrWddetIqXuseWdre27q576G6xHrrdY7ur3XJ62dYudqtsW7Be6IWqLFlWSys2\nZC3UlUtRGkhCCIRkhrn//vDM/BhynWRmPvOdPB/neEzme5n3vP0688p3Pt/P1xaLxWICAAAAkDV2\n0wUAAAAA4w0hHAAAAMgyQjgAAACQZYRwAAAAIMsI4QAAAECWEcIBAACALHOaLsAK2tra0rYvl8ul\n8vJydXZ2KhQKpW2/2eJ2uxUIBEyXkTL6bgZ9N4O+m0HfzaDvZpjs+7Rp07L6fJnCmXCkxG7nkDGB\nvptB382g72bQdzPo+/jFf3kAAAAgywjhAAAAQJYRwgEAAIAsI4QDAAAAWUYIBwAAALKMEA4AAABk\nGSEcAAAAyLKcuVnPnj171NLSoo6ODtXU1KipqWnA9VpaWrRnzx51dXXJ7XZr/vz5WrFihRwOhyTJ\n5/Pp+eef16FDh1RYWKgVK1ZowYIFie1bW1v18ssvy+fzadasWbr55ptVWFiYldcIAAAASDkUwouL\ni1VfX69Dhw4NeeelUCikG2+8UdOnT5fP59MzzzyjV199VcuWLZMk/exnP5PD4dBDDz2kEydO6Omn\nn9bUqVNVUVGhjo4Ovfjii7r99tt18cUX64UXXtD27dt12223ZetlAgAAALkzHKW6ulpVVVXyeDxD\nrrd48WLNnDlTTqdTJSUlmj9/vt59911JUjAY1P79+9XY2Ci3262ZM2eqsrJS+/btk/TeWfA5c+bo\nsssuk9vt1vLly3XgwAFL3i4WAAAA1pUzZ8JH6+jRoyovL5ckdXV1yW63q6ysLLF8ypQpOnr0qCSp\ns7NTl1xySWLZ5MmT5XA41NXVpWnTpkmSenp61Nvbm/QcwWBQRUVFaanX6XQm/dtqHA6HXC6X6TJS\nRt/NoO9m0Hcz6LsZ9N0Mq/c9F1i6c7/73e/U1tamD33oQ5LeC8tutztpnQkTJiTOdA+3XJL27t2r\nXbt2Ja3T0NCgxsbGtNbu9XrTuj+MDH03g76bQd/NoO9m0Hcz6PvoWTaEHzhwQC+99JLuuuuuxFnq\ngoKCfkNLAoFAIngPt1yS6urqVFlZmbROMBhUZ2dnWup2Op3yer3q7u5WOBxOyz6zye12W3L4Dn03\ng76bQd/NoO9m0HczTPY9PgLC6iwZwt9++2298MILuv322zVlypTE4xdddJGi0ai6urp00UUXSZJO\nnDiR+I9VXl6u9vb2xPqnTp1SOBxOrCtJJSUlKikpSXq+tra2IS8WHY1wOJz2fWaD0+m0ZN1x9N0M\n+m4GfTeDvptB382wat9zQc5cmBmJRBQKhRSLxRSLxRQKhRSJRPqtd/jwYW3btk0f/vCHNWPGjKRl\nBQUFqqqq0s6dOxUMBvXOO+/orbfe0sKFCyVJCxYs0FtvvaWjR48qGAxq586dqqqq6jdEBQAAAMik\nnDkT3tzcnDQWu7W1VQ0NDaqtrdWmTZu0bt06lZaWqrm5WefOndMPf/jDxLozZ87Uxz/+cUnS6tWr\n9dxzz+mxxx6Tx+PR6tWrVVFRIUmqqKjQmjVrtHXrVvn9/sQ84QAAAEA22WKxWMx0Ebmura0tbfty\nuVwqLy9XZ2enJb++8Xg88vv9pstIGX03g76bQd/NoO9mDNf3+DfsdnvOfPmfJF/7nknxGe2sLjeP\nSAAAgDRYuXJl0vTEQK4ghAMAgLzV3d1tugRgQIRwAAAAIMsI4QAAAECWEcIBAEDee+6550yXACQh\nhAMAgLz3zW9+03QJQBJCOAAAyHs2m810CUASQjgAAMh7hHDkGkI4AADIe4Rw5BpCOAAAyHuEcOQa\nQjgAAACQZYRwAAAAIMsI4QAAIO8xHAW5hhAOAADyFuEbuYoQDgAA8p7dTuRBbuGIBAAAeW+4M+Jt\nbW3q6urKUjUAIRwAAIwDw4XwxYsX67bbbstSNQAhHAAAQJJ05swZ0yVgHCGEAwCAvBU/Az5x4sRh\n13U4HJkuB0hwmi7ACtxud9ou6LDZbPL5fHK5XHI6rdd+u90uj8djuoyU0Xcz6LsZ9N0M+m7GcH2P\nf35fddVVw74+p9OZ9R7ka98xPLo2AoFAIG37crlcKi0tVV9fn0KhUNr2my0ej0d+v990GSmj72bQ\ndzPouxn03Yzh+h6LxXTLLbfIZrMN+/pGsk665WvfM8nr9Wb1+TKFEA4AAPJWLBZLuiizublZ3d3d\nA67LNIbIJkI4AADIW/EQHovFFIvFdPvtt2vNmjUDrrto0aIsV4fxjBAOAADyViwWk91uVywWUzgc\nlsPh0Le+9a1+602bNk0VFRUGKsR4xfcuAAAgb8ViMTkcDsViMYVCIblcLtMlAZII4QAAIE8FAgG1\nt7cnxnoHg0FCOHIGw1EAAEBeis86Yrfb9cYbb6impoYQjpxBCAcAAHkpPn91d3e3XnnlFfX09GjF\nihWGqwLeQwgHAAB5KRqNqri4WJFIRJL03HPPGa4I+P8YEw4AAPJSNBpNmiMcyCWEcAAAkJfi0xMS\nxJGLCOEAACAvXXi3TCCXEMIBAEBeikaj3IoeOYsjEwAA5CVCOHIZs6MAAIC8c/DgQT322GOMCUfO\n4s9DAACQd373u9/pxIkTevzxx02XAgyIEA4AAPJOKBTS5Zdfrvr6etOlAAMihAMAgLwTDAZVUFBg\nugxgUIRwAACQV2KxmM6dOyeXyyVJjAlHTiKEAwCAvPLP//zP2rhxo6ZOnWq6FGBQOTM7yp49e9TS\n0qKOjg7V1NSoqalpwPXa29u1Y8cOtbW1ye/3a8OGDUnLN27cmPR7OBzW4sWLtWrVKnV3d+uJJ55I\n/GUsSUuXLlVDQ0PaXw8AADDjzJkz+od/+Afdf//9pksBBpUzIby4uFj19fU6dOiQQqHQoOs5HA7N\nmzdPixcv1pYtW/otX79+feLnYDCoxx57TNXV1UnrPPzww3I4HOkrHgAAjFuvvvqq3n777VFtW1BQ\noGAwmOaKMs/hcKi4uFhnz55VTU2NFi1aZLoky8mZEB4Pym1tbUOG8LKyMpWVlamrq2vYfe7fv19F\nRUWaOXPmiOvo6elRb29v0mPBYFBFRUUj3sdQnE5n0r+txuFwJH2TYBX03Qz6bgZ9N4O+mzFQ3202\nm5xOZ+L1xG/YM9Trs9vtstvto+rBP/7jP2rq1KkqLy9PeVuHw6FIJJLydqbZ7Xa53W4FAgFNnz7d\nkseOadZ8pxihlpYWLVy4sN8FGfE5Q2fPnq2VK1cmBey9e/dq165dSes3NDSosbExrbV5vd607g8j\nQ9/NoO9m0Hcz6LsZ5/fd4/Fo4sSJiVDsdrslaciQXFhYmLRNqh555BFdddVVo9oW41PehvDTp0/r\n6NGjuvnmmxOPFRYW6v7779fUqVPl9/u1fft2bdu2TXfeeWdinbq6OlVWVibtKxgMqrOzMy11OZ1O\neb1edXd3KxwOp2Wf2RT/q9dq6LsZ9N0M+m4GfTdjoL77fD719fUlPrvjr2uoz3Kfz6fe3t5Rfd4H\nAgH19PSMatt86nu2jPYPpVyTtyF83759uvTSS5P+Mna73Zo+fbokaeLEiVq1apW+9rWv6dy5c5ow\nYYIkqaSkRCUlJUn7Gm6IzGiEw+G07zMbnE6nJeuOo+9m0Hcz6LsZ9N2M8/seiUQUjUYTv0ejUUka\n8vVFIhG1t7ePqgfxEDqabfOp70hNXofwpUuXDrkO84YCAABJOnjwoF555RX19fVJku69917NmTNn\nRNuGw2EmfEDKcmae8EgkolAopFgsplgsplAoNOCFChcuC4VC/b4Geeedd3T27FnNmzcv6fFjx47p\n5MmTikaj8vl8+vnPf67LLrsscRYcAABYXywWS/lE25EjRyRJVVVVOnDggH7729+OeNuenh5COFKW\nM2fCm5ubky6IbG1tVUNDg2pra7Vp0yatW7dOpaWlOn36tJ544onEehs3btSkSZP04IMPJh7bt2+f\nqqqqEhdixHV3d+vll19WX1+f3G63Zs2apVtvvTXzLw4AAGRVqiE8vv7atWv15ptvKhaLjXjbzs5O\neTyelJ4PyJkQ3tjYOOgMJOfP/e31evvdoOdCN91004CPz58/X/Pnzx91jQAAIPddGKBHEsjPX8dm\ns6UUwj0eT7/ryYDh5MxwFAAAgHRIJUCnYx/hcNiy88PDHEI4AADIO6MdjpKq+LVq3KwGqSKEAwCA\nvDLWM+GpDEeJRCKJu20CqeC7EwAAkHcuHOOd6rabNm3Sv//7vw+7bjQa5aJMjAohHAAA5JXRTFF4\nYWj/05/+pPXr12vFihXDbjtx4sSUawQI4QAAYNwbKLRPnz5dlZWVBqrBeEAIBwAAeSfV4SiPPPKI\n3n333aT1ubM2MokQDgAA8spohqPU19cnfo5vy8WWyCSOLgAAkFfSMTuKRAhHZnF0AQCAvDOWoSSE\ncGQDRxcAAMgro7lt/UAI4cgkji4AAJB30nEmnAszkUmEcAAAkFdGc2HmQDgTjkzi6AIAAHllrBdm\n+v1+SYRwZBZHFwAAyDtjuW39008/LYkQjszi6AIAAHllrGfC4xgTjkwihAMAgLxyYQh3u92j2g8h\nHJnEHTMBAEDeOT9Af+5zn9ONN96Y8j4YjoJMIoSPgNvtTtv/iDabTT6fTy6XS06n9dpvt9vl8XhM\nl5Ey+m4GfTeDvptB380YqO8Oh0NutzvxeubMmaM5c+akvG+Px5PxnuRT35EaujYCgUAgbftyuVwq\nLS1VX1+fQqFQ2vabLR6PJ3HVuJXQdzPouxn03Qz6nn3RaFSvvPKK7rrrrqS+h8NhBYPBMb+eUCiU\n8Z5Yse+S2ePd6/Vm9fkyhe9ZAACAJb355ptau3Ztv8eZJxxWwNEFAADyTjpCeElJSRoqAQZGCAcA\nAACyjBAOAAAsaaD5wF999VXt27dvTGfCrXihJKyHEA4AAPLGCy+8oMrKSi1dunTU+ygoKEhjRcDA\nCOEAACBvxGIxLV26VBUVFaPeh8PhkPTe7CtAphDCAQCAJQ00HCUajY75osz49uFweEz7AYZCCAcA\nAHllrFMLxkP42bNn01EOMCBCOAAAyBvRaHTMITx+ht2KN12CdRDCAQCAJQ00HCVdN+oZbP9AuhDC\nAQBA3kjHmfA4QjgyiRAOAADyRjpnNCGEI5MI4QAAIG/EYjHOhMMSCOEAACBvpGNMePxmPYRwZBIh\nHAAA5I10nAn/6le/Komb9SCzCOEAAMCSBrtZz1hD+HXXXTem7YGRIIQDAIC8kY47ZsYxHAWZRAgH\nAAB5IRgM6le/+hUhHJZACAcAAJZ0YUju6urSuXPnVF9fn5H9A+nkNF1A3J49e9TS0qKOjg7V1NSo\nqalpwPXa29u1Y8cOtbW1ye/3a8OGDUnLv//97+vYsWOJ8WAlJSX6zGc+k1je2tqql19+WT6fT7Nm\nzdLNN9+swsLCjL0uAACQWdu2bdOyZcsUjUZ18cUXq7S0NC37JYQjk3ImhBcXF6u+vl6HDh1SKBQa\ndD2Hw6F58+Zp8eLF2rJly4DrrFq1SnV1df0e7+jo0Isvvqjbb79dF198sV544QVt375dt912W9pe\nBwAAyK5bb71VHR0daZ0jXCKEI7NyJoRXV1dLktra2oYM4WVlZSorK1NXV1fKz9Ha2qo5c+bosssu\nkyQtX75c3/jGNxQIBOR2uyVJPT096u3tTdouGAyqqKgo5ecbiNPpTPq31TgcDrlcLtNlpIy+m0Hf\nzaDvZtD37HM4HImfnU6n7HZ7Wl9HNnpixb5L1j/ec0Fedu7ll1/WSy+9pLKyMi1fvlzve9/7JEmd\nnZ265JJLEutNnjxZDodDXV1dmjZtmiRp79692rVrV9L+Ghoa1NjYmNYavV5vWveHkaHvZtB3M+i7\nGfQ9e87vtdfrldfrldPpVHl5eVr2P2nSpLTtK19xvI9e3oXwlStXqry8XA6HQ2+++aaeeeYZPfDA\nA5o8ebKCwWDijHfchAkTFAgEEr/X1dWpsrIyaZ1gMKjOzs601Od0OuX1etXd3a1wOJyWfWaT2+1O\n6pdV0Hcz6LsZ9N0M+p593d3dST+fPHlSsVgsLZ/ZW7du1Qc+8IG0ff4Pxop9l8we7/nyh1HehfAZ\nM2Ykfl60aJH+93//V2+//bauvvpqFRQU9DvQzx+KIr13IWdJSUnSOsMNkRmNcDic9n1mg9PptGTd\ncfTdDPpuBn03g75nz/n1hsNhBQIB2Wy2tLyOa665RrFYLOM9sWLfz2fV4z0X5P0UhTabLXFhRXl5\nudrb2xPLTp06pXA4rIsuushUeQAAIE3SfWEmkEk5c6RGIhGFQiHFYrHEX56RSKTfehcuC4VCia9B\n/H6/Dh48mFje2tqqo0eP6vLLL5ckLViwQG+99ZaOHj2qYDConTt3qqqqqt8QFQAAkPsuvClPOm5Z\nD2RLzgxHaW5uTrogsrW1VQ0NDaqtrdWmTZu0bt06lZaW6vTp03riiScS623cuFGTJk3Sgw8+qGg0\nqldeeUUnT56UzWZTWVmZPvrRj6qsrEySVFFRoTVr1mjr1q3y+/2JecIBAID1xL/pXrZsmSRCOKwl\nZ0J4Y2PjoDOQrF+/PvGz1+vtd4OeuKKiIv3FX/zFkM+zYMECLViwYNR1AgCA3BIP3tFoNG23rAcy\njT8XAQBAXmBMOKyEIxUAAFha/Ow3w1FgJRypAADA0uIh/Pjx4zp37pzhaoCRIYQDAABLO3v2rHbs\n2KHNmzdr4sSJpssBRiRnLswEAAAYjddff10PPfSQTpw4oenTp5suBxgRzoQDAABLik9RKL1350np\nvXHhgBUQwgEAgOUFAgHTJQApIYQDAADLi58VP//sOJDLCOEAAMCSzg/cDEOB1RDCAQCA5RHCYTWE\ncAAAYEnn36I+EokYrARIHSEcAABYEsNRYGWEcAAAYHlckAmrIYQDAADLY3YUWA0hHAAAWBLDUWBl\nhHAAAGBJhHBYGSEcAABY0vkhnNlRYDWEcAAAYEkDnQlnTDiswmm6ACtwu92y29Pz94rNZpPP55PL\n5ZLTab322+12eTwe02WkjL6bQd/NoO9m0Pfsc7lcAz5upddhxb5L1j/ecwFdG4FAIJC2fblcLpWW\nlqqvr0+hUCht+80Wj8cjv99vuoyU0Xcz6LsZ9N0M+p59586d6/dYLBaz1OuwYt8ls8e71+vN6vNl\nCsNRAAAAgCwjhAMAAEtiRhRYGSEcAABYUklJiekSgFEjhAMAAEsqKirq9xizo8AqCOEAAMDSrrrq\nKq1cuVISIRzWwewoAADA0p566imVlZWpoqLCdCnAiHEmHAAAWFL8rLfNZjNcCZA6QjgAAACQZYRw\nAABgaZwJhxURwgEAgCX5fD5JySGcCzNhFYRwAABgSQONCSeEwyoI4QAAwJLigXvatGmGKwFSxxSF\nAADAkmKxmOrq6lRUVCSfz6cPfvCDKisrM10WMCKEcAAAYFnnD0X57ne/K7udL/lhDYRwAACQF1wu\nl+kSgBHjz0UAAGBZTE8IqyKEAwAAS2ImFFgZIRwAAFhSLBbjTDgsixAOAAAsixAOq8qZCzP37Nmj\nlpYWdXR0qKamRk1NTQOu197erh07dqitrU1+v18bNmxILAuHw9q+fbsOHz4sv9+vyZMna8WKFbri\niiskSd3d3XriiSeSLtxYunSpGhoaMvraAABA+jEcBVaWMyG8uLhY9fX1OnTokEKh0KDrORwOzZs3\nT4sXL9aWLVuSlkWjUZWUlOjuu+/WpEmT9Pbbb+vHP/6xPvnJT8rr9SbWe/jhh+VwODL2WgAAQOYx\nHAVWljMhvLq6WpLU1tY2ZAgvKytTWVmZurq6+i0rKChQY2Nj4vfKykqVlpbq+PHjSSEcAADkB0I4\nrCpnQngm9Pb2qqurS+Xl5UmPP/7445Kk2bNna+XKlSoqKkos6+npUW9vb9L6wWAwaZ2xcDqdSf+2\nGofDYcl5WOm7GfTdDPpuBn3PPofDkQjh9D27rH6854K87VwkEtHWrVu1aNGiRAgvLCzU/fffr6lT\np8rv92v79u3atm2b7rzzzsR2e/fu1a5du5L21dDQkHSGPR04M28GfTeDvptB382g79kzadKkRICl\n72bQ99HLyxAejUa1bds2ORwOrVq1KvG42+3W9OnTJUkTJ07UqlWr9LWvfU3nzp3ThAkTJEl1dXWq\nrKxM2l8wGFRnZ2daanM6nfJ6veru7lY4HE7LPrPJ7XYrEAiYLiNl9N0M+m4GfTeDvmff6dOnFYlE\nJIm+Z5nJ4/3CEQ5WlXchPBaL6fnnn1dfX5/uuOOOIS/AHGgcWUlJiUpKSpIeG26c+miEw+G07zMb\nnE6nJeuOo+9m0Hcz6LsZ9D17QqFQYoYU+m6GVfueC3JmnvBIJJL4nykWiykUCiX+uj3fhctCoVDS\nX2AvvviiOjs79bGPfazfGKtjx47p5MmTikaj8vl8+vnPf67LLrsscRYcAABYCxdmwqpy5kx4c3Nz\n0ljs1tZWNTQ0qLa2Vps2bdK6detUWlqq06dP64knnkist3HjRk2aNEkPPvigTp8+rb1798rhcOir\nX/1qYp2bbrpJCxYsUHd3t15++WX19fXJ7XZr1qxZuvXWW7P6OgEAQHowTzisLGdCeGNj46AXP65f\nvz7xs9frTbpBz/lKS0sHXSZJ8+fP1/z588dSJgAAyBHMEw4ry5nhKAAAAMB4QQgHAAAAsowQDgAA\nLInhKLAyQjgAALAsQjisihAOAAAsidlRYGWEcAAAYEkMR4GVEcIBAIBlEcJhVYRwAABgSQxHgZUR\nwgEAgGVxJhxWRQgHAACWxJlwWBkhHAAAWBIXZsLKCOEAAMCyCOGwKkI4AACwJIajwMoI4QAAwJIY\njgIrI4QDAADLIoTDqgjhAAAAQJYRwgEAgCWdOXNG4XDYdBnAqBDCAQCAJblcLkWjUdNlAKPiNF2A\nFbjdbtnt6fl7xWazyefzyeVyyem0Xvvtdrs8Ho/pMlJG382g72bQdzPoe/a5XC5NnjyZvhtg9eM9\nF9C1EQgEAmnbl8vlUmlpqfr6+hQKhdK232zxeDzy+/2my0gZfTeDvptB382g79kXDAYlSYWFhfQ9\ny0we716vN6vPlykMRwEAAJbEPOGwMkI4AACwJEI4rIwQDgAALIt5wmFVhHAAAGBJnAmHlRHCAQCA\nJXHbelgZIRwAAFgWIRxWRQgHAACWxHAUWBkhHAAAWBLDUWBlhHAAAGBZhHBYFSEcAAAAyDJCOAAA\nsCSGo8DKCOEAAMCyCOGwKkI4AACwJGZHgZURwgEAgCUxHAVWRggHAACWRQiHVRHCAQCAJTEcBVZG\nCAcAAJbEcBRYGSEcAABYFiEcVkUIBwAAlsRwFFiZ03QBcXv27FFLS4s6OjpUU1OjpqamAddrb2/X\njh071NbWJr/frw0bNiQt9/l8ev7553Xo0CEVFhZqxYoVWrBgQWJ5a2urXn75Zfl8Ps2aNUs333yz\nCgsLM/nSAABABhDCYWU5cya8uLhY9fX1qq2tHXI9h8OhefPm6eabbx5w+c9+9jM5HA499NBD+rM/\n+zNt375dHR0dkqSOjg69+OKLampq0kMPPSSXy6Xt27en/bUAAIDsYDgKrCpnQnh1dbWqqqrk8XiG\nXK+srExXXnmlysvL+y0LBoPav3+/Ghsb5Xa7NXPmTFVWVmrfvn2S3jsLPmfOHF122WVyu91avny5\nDhw4oEAgkJHXBAAAMocz4bCynBmOkg5dXV2y2+0qKytLPDZlyhQdPXpUktTZ2alLLrkksWzy5Mly\nOBzq6urStGnTJEk9PT3q7e1N2m8wGFRRUVFaanQ6nUn/thqHwyGXy2W6jJTRdzPouxn03Qz6nn0O\nh0MOh0MSfc82qx/vuSCvOhcMBuV2u5MemzBhQuJM93DLJWnv3r3atWtX0joNDQ1qbGxMa61erzet\n+8PI0Hcz6LsZ9N0M+p49EydOTHyu03cz6Pvo5VUILygo6De0JBAIJP4HHW65JNXV1amysjJpnWAw\nqM7OzrTU6HQ65fV61d3drXA4nJZ9ZpPb7bbk8B36bgZ9N4O+m0Hfs6+np0fBYFCS6HuWmTzeBxqS\nbEUph3Cfz6eDBw/2G7KxZMmStBU1WhdddJGi0ai6urp00UUXSZJOnDiR+I9VXl6u9vb2xPqnTp1S\nOBxOrCtJJSUlKikpSdpvW1ubQqFQWmsNh8Np32c2OJ1OS9YdR9/NoO9m0Hcz6Hv2RKPRxLhw+m6G\nVfueC1IK4U899ZQ+/elPq6CgIOkCSpvNpnfeeWdMhUQikcT/TLFYTKFQSHa7PTHWKy4WiykcDisS\niUiSQqGQbDabnE6nCgoKVFVVpZ07d+pDH/qQTpw4obfeekv33XefJGnBggX67ne/q6NHj+riiy/W\nzp07VVVV1W+ICgAAyH1cmAkrSymE/83f/I22bt2qlStXpr2Q5ubmpLHYra2tamhoUG1trTZt2qR1\n69aptLRUp0+f1hNPPJFYb+PGjZo0aZIefPBBSdLq1av13HPP6bHHHpPH49Hq1atVUVEhSaqoqNCa\nNWu0detW+f3+xDzhAADAejo7Oy05lAOQUgzhBQUFuu666zJSSGNj46AXP65fvz7xs9fr7XeDnvMV\nFhbqYx/72KDLFyxYkHTzHgAAYE0ej0fFxcWmywBGJaV5wh999FF97nOf08mTJzNVDwAAwIgxpBRW\nlVIInzNnjp5//nlNmTIlMTfnQOO2AQAAMo0x4bCylIaj3Hnnnbrrrrv0kY98ZNg7WwIAAGQat62H\nVaUUwru6uvSlL32JAx4AAAAYg5SGo9xzzz36wQ9+kKlaAAAARozhKLCylM6E/+Y3v9E3vvENbdy4\nUVOmTEla1tzcnNbCAAAAhsO387CqlEL4/fffr/vvvz9TtQAAAADjQkohfO3atZmqAwAAABg3Ugrh\nTz755KDL7r333jEXAwAAMFIINfWxAAAgAElEQVSMCYeVpRTCL7wo88SJEzp06JCuvfZaQjgAAMg6\nxoTDqlIK4Tt37uz32JNPPqkDBw6krSAAAAAg36U0ReFA7r77bn3ve99LRy0AAAAjxnAUWFlKZ8Kj\n0WjS7z6fT//xH/+h0tLStBYFAAAwEgxHgVWlFMKdTme/g3369On6zne+k9aiAAAAgHyWUgg/cuRI\n0u9FRUUqKytLa0EAAABAvkv5THhhYaG8Xm/ise7ubvn9fk2bNi3txQEAAAD5KKULM2+55RYdO3Ys\n6bFjx46pqakprUUBAAAA+SylEP7WW29p/vz5SY/Nnz9ff/jDH9JaFAAAwHCYHQVWllIIr6io0MGD\nB5MeO3jwoC666KK0FgUAADASzI4Cq0ppTPi9996rW2+9VRs3btSsWbN06NAh/f3f/70+8YlPZKq+\nnOB2u2W3j3lKdUnvvVn4fD65XC45nSm1PyfY7XZ5PB7TZaSMvptB382g72bQ9+xzOp2KxWL03QCr\nH++5IKWuPfzww3K5XHrooYf07rvv6tJLL9V9992nz33uc5mqLycEAoG07cvlcqm0tFR9fX0KhUJp\n22+2eDwe+f1+02WkjL6bQd/NoO9m0PfsC4VCstlsKiwspO9ZZvJ4P3+CECtL6fSu3W7XX//1X+sP\nf/iD+vr6dODAAT300ENJZ4m/8pWvpL1IAACAgTAcBVaVnjEW5/nyl7+c7l0CAAAAeSXtIZwrlQEA\nQDaQOWBlaQ/hfC0EAACyhdwBq0p7CAcAAAAwNIajAAAAAFmW9hC+bNmydO8SAACgH078wcpSnl39\nrbfe0r59+9Tb25v0+L333itJ+tnPfpaeygAAAIbBmHBYVUoh/Mtf/rK+9KUvaeHChSosLEw8brPZ\nEiEcAAAAwNBSCuGPP/64fvOb32jBggWZqgcAAGBEGI4CK0tpTLjH49HcuXMzVQsAAEBKGI4Cq0op\nhD/66KP6zGc+o+PHjysajSb9AwAAkC2/+MUv9MQTT5guAxi1lIaj3H333ZKk7373u4nHYrGYbDab\nIpFIWgsDAAAYzH//93+bLgEYk5RC+JEjRzJVBwAAQMoYjgKrGnEIj0QiWrt2rX75y1/K7XZnsiYA\nAAAgr414TLjD4dCRI0cY/w0AAIzjDDisLqULM7/4xS/qk5/8pI4ePapIJMKFmQAAwIj49ISEcVhV\nSmPCP/GJT0iSfvCDHyQe48JMAAAAIDVcmAkAAABkWUohfObMmZmqQ3v27FFLS4s6OjpUU1Ojpqam\nQdd97bXXtHv3boXDYVVVVWnNmjVyOp06ffq0Nm3alLRuKBTS9ddfryVLlujIkSPavHmzXC5XYvnq\n1au1aNGijL0uAACQfgxHgdWlFMLvvPPOQQ/2p556akyFFBcXq76+XocOHVIoFBp0vYMHD2r37t1a\nu3atiouLtWXLFu3cuVMrV65UaWmp1q9fn1i3u7tbX//611VVVZX0PJ///OfHVCsAAAAwFimF8Msv\nvzzp9xMnTugnP/mJ7rjjjjEXUl1dLUlqa2sbMoS3tLSotrZWFRUVkqSGhgZt3bpVK1eu7Lfuvn37\nNHPmTHm93hHX0dPTo97e3qTHgsGgioqKRryPoTidzqR/W43D4Uj6JsEq6LsZ9N0M+m4GfTfDbn9v\njgn6nl1WP95zQUqd++IXv9jvsfvuu0+PPPJI2goaTmdnp+bOnZv4fcqUKerr65PP51NhYWHSuvv2\n7VN9fX3SY319fXrsscfkcrk0d+5cLV++XAUFBYnle/fu1a5du5K2aWhoUGNjY1pfRyp/GCB96LsZ\n9N0M+m4Gfc+OWbNmSVLis5++m0HfR2/Mf74sWrSoX2jNpGAwmHSzoAkTJkiSAoFAUgg/evSoent7\nE2fYJamsrEwPPPCAysrKdObMGT377LP65S9/qZtuuimxTl1dnSorK/s9Z2dnZ1rqdzqd8nq96u7u\nVjgcTss+s8ntdisQCJguI2X03Qz6bgZ9N4O+Z1f8W3O/3y9J9D3LTB7v5eXlWX2+TEkphL/yyitJ\nv/t8Pm3ZsiUp6GZaQUFB0sEa//nCu3i2tLSouro66fHi4mIVFxdLeu8vt5UrV+rpp59OCuElJSUq\nKSlJ2tdwQ2RGIxwOp32f2eB0Oi1Zdxx9N4O+m0HfzaDv2RG/R0n83/TdDKv2PRekFMLvu+++pN+L\nioq0aNEiPfPMM2ktaijl5eVqb29XTU2NpPfGpRcVFSWdBQ+FQtq/f78+8pGPDLkvm82WuLoaAABY\nD7OjwKpyZp7w+B04Y7GYYrGYQqGQ7Ha7HA5H0noLFy7UT3/6U82fP1/FxcVqbm7uN8XggQMHNGHC\nBL3vfe/rV7/X69WkSZPU09Ojl156KWl8OQAAsAbCN6wupRBeW1ur3/3ud/0ev+qqq/T666+PqZDm\n5uakseWtra1qaGhQbW2tNm3apHXr1qm0tFRXXHGFrr32Wm3evFmhUEjV1dX9Lprct2+fFi5c2O9/\n0OPHj2vbtm3y+/0qLCzU3LlztWLFijHVDQAAso8QDqtLKYQfPHiw32OxWEyHDx8ecyGNjY2DzkBy\n/tzfkrRkyRItWbJk0H3deeedAz4+3HYAAMAarHgRJnC+EYXwu+66S9J7s4TEf4774x//qHnz5qW/\nMgAAgEF85StfMV0CMCYjCuGzZ88e8GebzaZrr71Wt912W/orAwAAAPLUiEJ4/CY911xzjW644YaM\nFgQAAADkO3sqK99www361a9+pfvuuy8xt/brr7/eb/5wAACAbOACTVhVSiH8X//1X/XJT35SV1xx\nhZqbmyVJHo9HX/jCFzJSHAAAwFC43wesKqUQ/vjjj+ull17Sww8/LLv9vU3nzp2rt956KyPFAQAA\nAPkopRB+9uxZXXLJJZL+/9c/oVBIBQUF6a8MAABgAOdPTxiJRAxWAoxeSiF82bJl/aYE+vrXvz7o\n/N4AAADp1t7enviZEA6rSulmPY8//riampr0b//2bzp79qwqKytVUlKiF154IVP1AQAADCoajZou\nARiVEYfwSCSiOXPm6NSpU2ptbdU777yjSy65RO9///sT48MBAAAy7fyLMQnhsKoRh3CHw6E5c+ao\nu7tbV199ta6++upM1gUAADAsQjisKqXhKHfccYfWrFmjv/qrv9KMGTOS5uZcvnx52osDAAC40Pln\nwk+dOmWwEmD0Ugrh3/zmNyVJGzZsSHrcZrPp8OHDaSsKAABgJH7/+9+bLgEYlZRC+JEjRzJVBwAA\nQMr27t1rugRgVLiiEgAAWAp3yUQ+IIQDAABLYRw48gEhHAAAWMpTTz1lugRgzAjhAADAMv7u7/5O\ne/bsMV0GMGa2GAOrhtXV1ZW2GxLZbDYVFBQoGAxackyb3W635Jys9N0M+m4GfTeDvmfH5MmT+z3W\n19dH37PM5PHu9Xqz+nyZktLsKONVIBBI275cLpdKS0vV19enUCiUtv1mi8fjkd/vN11Gyui7GfTd\nDPpuBn03p7CwkL5nmcnjPV9COMNRAAAAgCwjhAMAAABZRggHAAAAsowQDgAAAGQZIRwAAADIMkI4\nAAAAkGWEcAAAYBkDzRMOWBEhHAAAWIbL5TJdApAWhHAAAGAZVrwrJjAQQjgAALAMQjjyBSEcAABY\nBiEc+YIQDgAALIMQjnxBCAcAAJZBCEe+IIQDAADLIIQjXxDCAQCAZRDCkS8I4QAAwBL279+v06dP\nJz32hS98wVA1wNgQwgEAgCWcOHFC11xzTdJj3LwHVkUIBwAAlhAOh1VcXGy6DCAtnKYLAAAAGMiF\n478DgUC/M9+MEYdV5VQI37Nnj1paWtTR0aGamho1NTUNuu5rr72m3bt3KxwOq6qqSmvWrJHT+d7L\n+Zd/+Rf19fXJZrNJki655BLdddddI9oWAADkhgceeEAvvvhi0mNr1641VA2QXjmVPIuLi1VfX69D\nhw4pFAoNut7Bgwe1e/durV27VsXFxdqyZYt27typlStXJtb52Mc+ptmzZ49qWwAAYN7p06f1zDPP\nqL6+PunxzZs3J37mTDisKqdCeHV1tSSpra1tyBDe0tKi2tpaVVRUSJIaGhq0devWEQXp4bbt6elR\nb29v0jbBYFBFRUWjek0Xip9xt+qZd4fDYcmLYOi7GfTdDPpuBn1PP5vNJqfTOWRd8W+96Xt2Wf14\nzwWW7FxnZ6fmzp2b+H3KlCnq6+uTz+dTYWGhJGnbtm2KxWKaOnWqrr/+ek2dOnVE2+7du1e7du1K\ner6GhgY1Njam9TV4vd607g8jQ9/NoO9m0Hcz6Hv6uFwulZaWqry8fNB1PB6PJPpuCn0fPUuG8GAw\nKLfbnfh9woQJkt67YKOwsFC33nqrLr74YsViMe3Zs0c/+MEP9OlPf1oej2fYbevq6lRZWdnv+To7\nO9NSu9PplNfrVXd3t8LhcFr2mU1ut1uBQMB0GSmj72bQdzPouxn0Pf1CoZBOnz495Gew3++XJPqe\nZSaP96H+KLMSS4bwgoKCpAM2/nM8XF966aWJZcuWLVNLS4veeecdVVZWDrttSUmJSkpKkp5vuOEx\noxEOh9O+z2xwOp2WrDuOvptB382g72bQ9/SJRqOKRCJD1hUPgPTdDKv2PRdYcp7w8vJytbe3J34/\nceKEioqKEkNRLmSz2RIXbqS6LQAAMIOLLpHPciqEx//ajcViisViCoVCikQi/dZbuHCh3njjDXV0\ndMjv96u5uVmLFi2S9N6V1O+8807iL7P/+Z//kc/nS5wdH2pbAAAAIBtyajhKc3Nz0kWRra2tamho\nUG1trTZt2qR169aptLRUV1xxha699lpt3rxZoVBI1dXViQsng8GgXnzxRXV3d8vpdGrq1Km64447\nEme6h9oWAADklvjsJ4PhbDmsKqdCeGNj46CBeP369Um/L1myREuWLOm3XkVFhT71qU8N+TyDbQsA\nAKyF2TlgVTkVwgEAAOKGO8u9d+9eTZ8+PUvVAOmVU2PCAQAAzjfUcJSpU6fKbifKwJo4cgEAAIAs\nYzgKAAzgP//zP3XkyBFL3vzDbrersLBQPp9P0WjUdDkpczqd9N2AXOq70+nUX/7lXw66fPLkyTp1\n6lQWKwLSjxAOAAP45je/qZUrV2ry5MmmS0mZ3W7XxIkT1dvba8kw6HK5LHnzD/qePt/+9rd1yy23\nSBp+dhTAqgjhADCASCSitWvXasaMGaZLSZnL5VJ5ebk6OztzJlSlwuPxJG5FbiX0PX1+8pOfDHlR\nJtMSIh8wJhwABhCJROR0cp4CMCF+p2vCNvIZIRwABhAOhwnhgCHxEB7/GchHhHAAGEAkEpHD4TBd\nBgAgT3GaB0BOePnll/Xaa6+ZLiPhzJkzhHDAoKGGozBMBfmAEA4gJ2zZskUTJkxQVVWV6VIkSevX\nr1d5ebkCgYDpUoBx5/whKAxHQb4ihAPIGTfeeKNWr15tuowE7sQHmHH+mHAgX/EJAyAnxGIxzngB\nkMTsKBgfCOEAcgIftgCA8YQQDiBncCYcgMQUhRgfCOEAcgLDUQDEMRwF4wEhHEBOIIQDiBvuwkzC\nOfIBIRxATuBDFUAcUxRiPGCKwhFwu91pm6rMZrPJ5/PJ5XJZ8pbYdrtdHo/HdBkpo+9mpNJ3h8Mh\nt9udU69zPPQ9F9F3M3Kp73a7XQUFBbLb7UO+L3g8HvpuiNX7ngvo2gik82YdLpdLpaWl6uvrUygU\nStt+s8Xj8cjv95suI2X03YxU+h4OhxUMBnPqdY6Hvuci+m5GLvU9Fovp3LlzikQiCgQC/eqK99fv\n99N3Q0z23ev1ZvX5MoXhKAByAmPCAZxvqNlRCgoKsl0OkHaEcAA5gTHhAOKGuzCzpKQki9UAmUEI\nB5AzOBMO4HyDBXHeK5APCOEAcgYfrACk4d8LeK9APiCEA8gJjAkHEDfccBQgHxDCAeQEPnABxHHH\nTIwHhHAAOYEz4QDizj8TPtD7Au8VyAeEcAA5gw9WAMB4QQgHkBM4Ew4gbrjhKLxXIB8QwgHkBMZ+\nAohjOArGA25bD8CoWCymtrY2zoQDSGCKQowHnAkHYNTvf/97vf/97zddBoAcw7djyHeEcABG+Xw+\nSYwJB5CM4SjId4RwAEbFP0w56wUgjuEoGA8I4QCMstvfexviTDiA8zE7CvIdIRyAUfEQLvHBCuA9\nw922nvcK5ANCOACjzv8w5YMVgDT8+wLvFcgHhHAARsXPhL/22muKRqOGqwEAIDsI4QCMOn84yv79\n+w1WAiBXDHfHTCAf5MzNevbs2aOWlhZ1dHSopqZGTU1Ng6772muvaffu3QqHw6qqqtKaNWvkdDrV\n29urX/ziF/rjH/+oUCikiooK3XDDDZoxY4Yk6ciRI9q8ebNcLldiX6tXr9aiRYsy/voADI+vmAFI\nDEfB+JAzIby4uFj19fU6dOiQQqHQoOsdPHhQu3fv1tq1a1VcXKwtW7Zo586dWrlypYLBoKZNm6Yb\nbrhBRUVFeuONN/TDH/5Qn/3sZ+V2uxPP8/nPfz5bLwvAMM4/Ew4AcUOdBV+8eDFnyWF5OfPpV11d\nraqqKnk8niHXa2lpUW1trSoqKuTxeNTQ0KCWlhZJ0uTJk7VkyRIVFxfLbrfrqquuUiQSUVdXVzZe\nAoBRIIQDuNBww1EeeeQR/fSnP81yVUB65cyZ8JHq7OzU3LlzE79PmTJFfX198vl8KiwsTFr3+PHj\nikQimjx5cuKxvr4+PfbYY3K5XJo7d66WL1+ugoKCxPKenh719vYm7ScYDKqoqCgt9TudzqR/W43D\n4UgazmMV9N2MkfT9/P//nE5nTr3OfO57LqPvZuRS3+12u5xOp2w2m1wuV7+6XC5X4jOfvpth9b7n\nAst1LhgMJoaWSNKECRMkSYFAICmEnzt3Ts8++6yuu+66xDplZWV64IEHVFZWpjNnzujZZ5/VL3/5\nS910002J7fbu3atdu3YlPWdDQ4MaGxvT+jq8Xm9a94eRoe9mDNX3kydPJn6eOHGiysvLs1HSuMDx\nbgZ9H7uCggKVlJTI6XTK6/WO6H2BvptB30fPciG8oKBAgUAg8Xv85/ODeSgU0jPPPKMZM2Zo2bJl\niceLi4tVXFws6b2DZuXKlXr66aeTQnhdXZ0qKyuTnjMYDKqzszMt9cffULq7uxUOh9Oyz2xyu91J\n/bcK+m7GSPre3d2d+Lm3tzdt/6+lQz73PZfRdzNyqe+hUEinT5/W3r171d7ePuT7An03w2Tf8+Vk\njeVCeHl5udrb21VTUyNJOnHihIqKihJnwcPhsLZs2aLi4mKtWbNmyH0NdEeukpISlZSUJD3W1tY2\n5MWioxEOh9O+z2xwOp2WrDuOvpsxVN/Pf/OORCI59Trzue+5jL6bkWt9j783HD58WLW1tSNaP5fq\nH6lc63uqrNr3XJAzV0TFP3zjF2KEQiFFIpF+6y1cuFBvvPGGOjo65Pf71dzcnJhiMBKJ6Ec/+pGc\nTqeampr6XfB15MgRnT59WrFYTGfOnNFLL72UNL4cAADkBmY/Qb7LmTPhzc3NSWOxW1tb1dDQoNra\nWm3atEnr1q1TaWmprrjiCl177bXavHmzQqGQqqurE+O13333Xf3f//2fnE6nvvKVryT29fGPf1wz\nZ87U8ePHtW3bNvn9fhUWFmru3LlasWJF1l8rgIFdeHE1gPGLEI58lzMhvLGxcdCLH9evX5/0+5Il\nS7RkyZJ+61122WXasGHDoM8x2HYAcsPKlStNlwAgB3AzHowHOTMcBQCsOE0XgPQLBAKKRqOmywAy\nKmfOhAMAAEjS7t27dezYMUmcFUf+IoQDGRQMBvXtb397zFeOO51OS069ZbfbVVRUpL6+vkHPah06\ndCjxMx+2AOL++Mc/SuJ9AfmLEA5k0Lvvvqtvfetbuueee8a0n2g0atmvZuO1D1b/n/70p8TPfNgC\nAMYLQjiQQdFoVGVlZXrooYfGtB+PxyO/35+mqrLH5XKpvLxcnZ2dg34bMHPmTP32t7/NcmUAAJjF\nhZlABkUiETkcDtNl5LTzz35zJhzAhZiqEPmKEA5kUDgcJoQPgxAOYCiEcOQrQjiQQdFolBA+DII3\ngKFY9XoYYDiEcCCDwuGwnE4uvRgKZ8IBDOXGG280XQKQEaQDWILf79fSpUvl8/lGvQ+bzZb1rzXD\n4bDq6uqy+pxWQwgHMJTi4mLTJQAZQQiHJZw7d04+n0+//vWvR7W9y+VSWVmZTp48OeY5u1Pl8Xiy\n+nxWQ/AGAIxHhHBYQiwWk91u16RJk0a1vcvlUmlpqUKhUNZDOEaOQA4AGC8YEw5LiMViBDQAAJA3\nCOGwBEJ4/uK/KwBgPCKEwxLiw1GQf7gwEwAwHpFqYAnRaJSAlqfO/+/qcrkMVgIAQPYQwmEJDEfJ\nX+f/d+XbDgDAeMEnHiyB4Sj5i+EoAIDxiCkKR8DtdqctANpsNvl8PrlcLkveSdFutxuZ99rtdstm\ns436uem7GSPpu9vtTvyca68xn/uey+i7Gbna9+Fqou9mWL3vuYCujUAgEEjbvuLzVff19VlyvmqP\nxyO/35/1540/52ifm76bMZK+n/94rr3GfO57LqPvZuRq34erib6bYbLvXq83q8+XKXy/D0tgTHj+\nmjFjhukSAOSYu+++W0VFRabLADKKEA5LYEx4/qqpqdGbb75pugwAOWTjxo1avny56TKAjCLVwBKY\nojC/MTUhgAvxno98RwiHJTAcJb9NnDhRBw4cMF0GgBzCez7yHSEclhAIBCx54QpGrqSkxHQJAABk\nDSEclhAKheRwOEyXAQDIEs6EI98RwmEZF110kekSAABZQghHviOEwxKi0SizowAAgLxBqoElEMIB\nYHwJh8OmSwAyilQDS2CKQgAYXyZMmGC6BCCjCOGwBEI4AIwvEydONF0CkFGEcFgCd8wEgPGFEy/I\nd6QaWAIhHAAA5BNSDSyBCzMBYHzhTDjyndN0ARjfurq6FIlEBlxms9lUVlYmm81GCAeAcebUqVOm\nSwAyihAOY958802tXr1aXq93wOVnzpzR9773PS1fvlxtbW0KBoNZrhAAYIrTSURBfuMIhzF9fX26\n8sor9eyzzw64/P7771dfX58k6fjx49wxEwDGEb79RL7jCIcx4XBYDodj0OUOh0PRaFSSdO7cOc2f\nPz9bpQEADGNMOPIdIRzGRCKRIUO43W5PhPA//elP3LgBAMYRQjjyXU4NR9mzZ49aWlrU0dGhmpoa\nNTU1Dbrua6+9pt27dyscDquqqkpr1qxJjB/r7u7Wc889p2PHjmnSpElatWqVZs+ePaJtkT2RSGTI\nvjscjsRFm36/Xy6XK1ulAQAMYzgK8l1OHeHFxcWqr69XbW3tkOsdPHhQu3fv1tq1a/XZz35W3d3d\n2rlzZ2L51q1bNXXqVP3t3/6tVqxYoR/96EeJscXDbYvsGW44yvlnwiORiKZNm5at0gAAADIqp0J4\ndXW1qqqq5PF4hlyvpaVFtbW1qqiokMfjUUNDg1paWiRJJ0+e1PHjx9XY2CiXy6Xq6mpNmTJF+/fv\nH3ZbZNdIzoTHQ3gwGFRBQUG2SgMAGMZwFOQ7S47B6Ozs1Ny5cxO/T5kyRX19ffL5fOrs7JTX65Xb\n7U5a3tnZOey2hYWF6unpUW9vb9LzBYNBFRUVpaX2eOgcLHzu2LFDO3bsSMtzZcL5Q0TG6ujRoyou\nLh50mInT6VQwGFQwGFQgEFBhYeGoh6QM1/dc53A4LDkch76bQd/NoO/pFe/jcDXRdzOs3vdcYMnO\nBYPBpJAdv2AvEAj0WxZf3tPTM+y2hYWF2rt3r3bt2pW0fUNDgxobG9P6GgabG7uyslJnz55N63Pl\nqg984AO66qqrVF5ePuDyyy+/XI8++qgeffRRORwOVVZWDrruSA3Wd2QWfTeDvptB39OjsLBQkkb8\nvk/fzaDvo2fJEF5QUKBAIJD4Pf6z2+3utyy+PB68h9pWkurq6lRZWZm0fTAYTJxJHyun0ymv16vu\n7m6Fw+F+y2fOnKmZM2em5bkywe129+vvWA3W23Xr1mndunUjWnc4w/U912Wi79lA382g72bQ9/SK\n1zLc+z59N8Nk38d6Qi5XWDKEl5eXq729XTU1NZKkEydOqKioSIWFhSovL1d3d3dS8D5x4kRijumh\ntpWkkpISlZSUJD1fW1ubQqFQWl9DOBxO+z6zwel0WrLuOPpuBn03g76bQd/TIxaLSdKIa6LvZli1\n77kgpy7MjEQiCoVCisViisViCoVCA44/Xrhwod544w11dHTI7/erublZixYtkiSVlZVp6tSp+q//\n+i+FQiEdOHBA7e3tqq6uHnZbAACQG7gwE/kup86ENzc3J43Hbm1tVUNDg2pra7Vp0yatW7dOpaWl\nuuKKK3Tttddq8+bNCoVCqq6uThqz/ed//uf66U9/qn/6p3/SpEmT9OEPfzhxYeVw2wIAAPMI4ch3\nORXCGxsbBw3E69evT/p9yZIlWrJkyYDrer1e3XPPPYM+z1DbAgAA8wjhyHc5NRwFAABAIoQj/xHC\nAQBAzrlwkgQg3xDCAQBAzvnUpz6l5uZm02UAGUMIBwAAOcftdmv27NmmywAyhhAOAAAAZBkhHAAA\nAMgyQjgAAACQZYRwAAAAIMsI4QAAAECWEcIBAACALCOEAwAAAFlGCAcAAACyjBAOAAAAZBkhHAAA\nAMgyQjgAAACQZYRwAAAAIMsI4QAAAECWEcIBAACALCOEAwAAAFlmi8ViMdNF5Lquri7Z7en5e8Vm\ns6mgoEDBYFBWbL3dblc0GjVdRsrouxn03Qz6bgZ9N4O+m2Gy716vN6vPlylO0wVYQSAQSNu+XC6X\nSktL1dfXp1AolLb9ZovH45Hf7zddRsrouxn03Qz6bgZ9N4O+m2Gy7/kSwhmOAgAAAGQZw1GyrKen\nR3v37lVdXZ1KSkpMlzNu0Hcz6LsZ9N0M+m4GfTeDvo8dZ8KzrLe3V7t27VJvb6/pUsYV+m4GfTeD\nvptB382g72bQ97EjhCrLPHcAAAzUSURBVAMAAABZRggHAAAAsowQDgAAAGSZY8OGDRtMFzGexGIx\nFRQU6LLLLpPb7TZdzrhB382g72bQdzPouxn03Qz6PnbMjgIAAABk2bi6WU84HNb27dt1+PBh+f1+\nTZ48WStWrNAVV1whSTp8+LC2b9+uM2fOaMaMGbrllltUWloqSXrzzTf161//WidOnND06dN1zz33\nJO378OHD2rFjh06dOqXCwkItXbpUV1111aC1dHd367nnntOxY8c0adIkrVq1SrNnz5Yktbe3a8eO\nHWpra5Pf79dIvqx47bXXtHv3boXDYVVVVWnNmjVyOp06ffq0Nm3alLRuKBTS9ddfryVLlqTSvlEb\nj32XpHfeeUe/+MUvdPLkSZWWlmr16tWaOXPmaFo4Kvna9+HW37Nnj1paWtTR0aGamho1NTWl2Lmx\nGa9937p1q44cOaJgMKiJEyfq2muvVV1dXYrdG73x2vfvf//7OnbsWOKuziUlJfrMZz6TSuvGZLz2\nfePGjf36sHjxYq1atWokbRuz8dr3zs5Obd++XcePH1dhYaGuv/56VVVVpdi93DGuhqOEw2F1dHTo\nxhtv1Ac/+EGVlJToJz/5iWpqahSNRvXkk0/qxhtv1M0336yuri69+uqriQ+Rs2fPaurUqSorK9Pp\n06dVW1ub2G8kEtF3vvMdLVu2TB/+8Id16aWXauvWrZozZ44mTpw4YC0//OEPNW3aNN15552aNGmS\ntm3bpiuvvFIFBQU6d+6c3G635s+frzfffFPXXXfdkK/r4MGD2rFjh9auXauGhga9/vrrOnXqlGbP\nnq0JEyaovr4+8c/8+fP1m9/8RmvWrJHH40lbb4cyHvvu8/n0ve99Tx/84AfV1NQkt9utZ599VnV1\ndXK5XGnr7VDyte/Drd/T05P4ejQajWb9DXq89r2srEyNjY1qaGjQrFmz9Oyzz+p973ufiouLx9TP\nkRqvfW9padHSpUv1kY98RPX19br66qvH1MdUjde+n/+5es011+jXv/61VqxYkQi6mTYe+x6JRPTk\nk09q/vz5+uhHP6opU6boxz/+saqrq1VYWDjmnpowri7MLCgoUGNjo7xer+x2uyorK1VaWqrjx4/r\nwIEDKi8v17x58+RyuXTdddepvb1dnZ2dkqTZs2erpqZmwA8Uv9+vQCCgBQsWyGazafr06SovL09s\ne6GTJ0/q+PHjamxslMvlUnV1taZMmaL9+/dLeu/D7Morr1R5efmIXldLS4tqa2tVUVEhj8ejhoYG\ntbS0DLjuvn37NHPmzKze8nU89v3dd9/VxIkTNW/ePNntdi1cuFCFhYU6cODAaFo4Kvna9+HWr66u\nVlVVVdb+yLzQeO17RUVF4lsgm+3/tXcvMXFVcRzHf8OQimV4ChkEeQi0BmiBmBjFmFSrLDAQmzZt\nociCjWl01VVj4qZJN7pSoztdEaWpaLSgTVCjmGBiSMqz0PB+pJEOMNAyiMNlZlw0TJhSLIXpHej9\nflYDc+acc3+5Gf4z99yDTTabTW63e0t9h4NVc480cpf6+/sVGxtr6pVOK+Y+OzurxcVFlZWVKSoq\nSrm5ucrMzFRPT89WY9t1LFWE38vj8Whubi54gqWlpQWf27dvn5KSkjY98dZzOBw6dOiQurq65Pf7\nNTU1pYWFBWVlZd23/czMjJKSkkJuZHA6nVsaa7P+1s/d6XRqaWlJ//zzz4a23d3dKikp2dY44WKV\n3O93u4XL5drWWOHwuOS+11gp95aWFl28eFGfffaZHA5H8NJ4JFgp919//VUffvihvvzyS42NjT2y\ncbbCSrmv6erqUklJiWw22yMfazNWzH1NJP+u7pSl1oSv5/P59O2336q0tFSpqalaWVnZcDkjJiZG\nXq93S/0dPnxYV65c0dWrVyVJlZWVSkhIuG/blZWVDXcSx8TE6M6dO9s4ko39xcTESJK8Xm/IMU1M\nTMjj8aiwsHBb44SDVXLPzMzU4uKient7VVhYqN7eXrndbhmGsa2xdupxyn0vsVrulZWVevPNNzU1\nNaXx8fHgN+Nms1Lu5eXlSk1Nld1uV19fnxobG3X27FklJyc/kvH+j5VyX7OwsKCJiQm99dZbj3Sc\n/2OV3FNSUhQbG6v29naVlZVpbGxM4+PjevbZZ8M+llksWYT7/X599913stvtwZso9u3bt+EE9Xq9\nW9p2Z2ZmRt98842qq6uVm5srt9utr7/+WnFxcTp48KA+//xzLSwsSJLefvvtHY3V09Oj5uZmSVJ2\ndvZ9+1t7fG9/XV1dKiwsjNhWQlbKff/+/aqpqVFra6t+/PFH5efnKzc3V/Hx8Q8cK9wet9z3Cqvm\nHhUVpezsbPX09Kijo0MvvfTSll8bDlbL/Zlnngk+Li0tVW9vr4aGhkxfG2613Nd0d3crKyvL1CWe\n61kpd7vdrurqal29elXt7e1KT09XUVFRxD7sh8Penfk2BQIBXblyRUtLS6qtrZXdbpckpaamqru7\nO9huZWVFbrd7S+uYXC6XUlJSlJ+fL+nup7UDBw5oaGhIBw8e1HvvvRfSfnZ2VvPz8yEn6vT0tA4f\nPvzAsYqLi1VcXBzyu9TUVN26dUuHDh0K9hUbGxvySdgwDPX39+v06dMPHONRsGLuOTk5eueddyTd\n/abi008/NW1HmjWPY+57AbnfLQ7m5+d31MfDIve76/HN3nnYyrl3d3frlVde2dZrd8qKuaelpYXs\n5vLFF1+otLT0ofrYTSy3JrylpUUzMzOqqakJ2aWioKBALpdL/f39MgxDbW1tcjqdwZPW7/fLMAz5\n/X4FAgEZhiGfzydJevrppzU3N6fR0VEFAgG53W4NDg6GrMlaLyUlRWlpafr9999lGIYGBgZ069at\n4DKRe/s3DEOrq6ubHlNJSYmuXbsml8ul5eVl/fHHHxtOyoGBAcXExETsso0Vc//777/l8/n077//\nqrW1VfHx8cE3NrM8jrk/qL3P55NhGAoEAhvamsVquXs8HvX29srr9crv92t4eFh9fX2mv99YLffl\n5WUNDw8Hn+/p6dHExATvMya8z0h3t6FdXFxUUVHRNpPbGSvmPj09LcMwtLKyovb2dnk8nj1dhFvq\nn/UsLCzo448/lt1uD+6pKklVVVUqLi7WyMiIfvrpJ92+fVsZGRk6duxY8BJTZ2enfvjhh5D+SkpK\ngnsQ9/X1qa2tTbdv39YTTzyh4uJivf766yHjrDc/P6/vv/9eN2/e3LCv5vz8vD755JOQ9gkJCTp3\n7tymx/bnn3+qvb1dhmGosLAwZL9qSWpoaFBGRoaOHj36EImFh1Vzb2pq0tDQkCQpPz9fFRUVm27x\n9Cg8rrk/qP1vv/2mtra2kOePHDmi11577X/zChcr5r60tKTLly9renpagUBAiYmJevHFF03dJ9yq\nuX/11VeanZ2VzWZTSkqKjh49GhzLDFbMfU1zc7MMw9Dx48e3ElVYWTX31tZWXbt2TT6fT9nZ2aqo\nqNBTTz211dh2HUsV4QAAAMBuYLnlKAAAAECkUYQDAAAAJqMIBwAAAExGEQ4AAACYjCIcAAAAMBlF\nOAAAAGAyinAAAADAZBThAAAAgMkowgEAAACTUYQDAAAAJqMIBwAAAExGEQ4AAACYjCIcAAAAMBlF\nOAAAAGAyinAAAADAZBThAAAAgMkowgFgF5ucnJTD4ZDP54v0VAAAYUQRDgC7TE5Ojn755RdJUlZW\nljwej+x2e4RnBQAIJ4pwAAAAwGQU4QCwi9TV1WlyclJVVVVyOBz66KOPZLPZtLq6Kkl69dVX9cEH\nH+jll1+Ww+FQVVWV5ubmVFtbq/j4eL3wwgsaHx8P9nfjxg2Vl5crOTlZzz33nC5fvhyhIwMArEcR\nDgC7SENDg7KystTc3CyPx6NTp05taHPp0iU1NDTo5s2bGhkZUVlZmerr6+V2u1VQUKALFy5IkpaW\nllReXq4zZ87I5XKpsbFR7777rq5fv272YQEA7kERDgB7TH19vfLy8pSQkKCKigrl5eXpjTfeUHR0\ntE6ePKnOzk5JUktLi3JyclRfX6/o6Gg9//zzOnHihJqamiJ8BACA6EhPAADwcJxOZ/Dxk08+ueFn\nj8cjSZqYmNBff/2lxMTE4POrq6uqq6szb7IAgPuiCAeAXcZms4Wln8zMTB05ckQ///xzWPoDAIQP\ny1EAYJdxOp0aHR3dcT+VlZUaHBxUQ0ODDMOQYRjq6OjQwMBAGGYJANgJinAA2GXef/99Xbx4UYmJ\niTtavx0XF6fW1lZdunRJ6enpSktL0/nz5+X1esM4WwDAdtgCgUAg0pMAAAAArIRvwgEAAACTUYQD\nAAAAJqMIBwAAAExGEQ4AAACYjCIcAAAAMBlFOAAAAGAyinAAAADAZBThAAAAgMkowgEAAACT/Qew\nqLnPRl5zLAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb99f0157b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<ggplot: (8777364135779)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEE_BUY=0\n",
    "FEE_SELL=0\n",
    "#eval_model(test,-999)['kpis']\n",
    "kpi_obj=eval_model(test,0.99)\n",
    "kpi_data = kpi_obj['data']\n",
    "kpi_data['time'] = [datetime.fromtimestamp(e) for e in kpi_data.timstamp.values]\n",
    "print(kpi_obj['kpis'])\n",
    "from ggplot import *\n",
    "p=ggplot(aes(x='time', y='return_cum'), data=kpi_data) #[kpi_data['return'] != 1.0]\n",
    "p + geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPOT genetic algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from tpot import TPOTClassifier\n",
    "TYPE=\"classify\"\n",
    "TRAIN_STRATEGY = \"NONE\"\n",
    "MODEL={'scoring' : 0}\n",
    "THRES_PROF = 0.00402\n",
    "TARGET_TIME = 800\n",
    "TRAIN_THRES=0.012\n",
    "N_TRAIN = 200000\n",
    "\n",
    "d=prep_data(dr)\n",
    "FEATURES = d.filter(regex=('width$|^(imba)|^(adj)|^(tr)|^(t[0-9])|^(agg)|(mid$)')).columns\n",
    "\n",
    "tpot = TPOTClassifier(generations=10, population_size=20, verbosity=2,\n",
    "                      scoring=\"log_loss\",random_state=1,n_jobs=12,cv=TimeSeriesSplit(max_train_size=200000,n_splits=3,))\n",
    "\n",
    "splits=10\n",
    "cv=TimeSeriesSplit(n_splits=splits,max_train_size=400000)\n",
    "i_train, i_test = [i for i in cv.split(d)][splits-1]\n",
    "print(i_test.shape)\n",
    "X=d.iloc[i_train,:]\n",
    "X = X[(X.target >= TRAIN_THRES) | (X.target < THRES_PROF) ]\n",
    "test = d.iloc[i_test,:]\n",
    "\n",
    "tpot.fit(X[FEATURES], X.target_cat)\n",
    "y_pred_prob2 = tpot.predict_proba(test[FEATURES])\n",
    "test['y_pred_prob'] = np.asarray([p[1] for p in y_pred_prob2 ])\n",
    "\n",
    "#tpot.export('tpot_mnist_pipeline.py')\n",
    "#t=tpot.clean_pipeline_string\n",
    "'''\n",
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression pipeline (imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#--------regression pipe\n",
    "pipe=ImbPipe([\n",
    "            ('ft', FunctionTransformer(transform_features,validate=False)),\n",
    "            ('rs', StandardScaler()), \n",
    "            ('pca',PCA()),\n",
    "            ('enet',ElasticNet(random_state=1,alpha=0.001,l1_ratio=0))\n",
    "])\n",
    "\n",
    "params = {\n",
    "          'enet__alpha': [0.001,0.005,0.01],\n",
    "         'enet__l1_ratio': [0,0.001,0.01]\n",
    "         }\n",
    "grid0 = GridSearchCV(estimator=pipe,refit=True,param_grid=params,n_jobs=16,verbose=0,\n",
    "                    cv=TimeSeriesSplit(n_splits=2),\n",
    "                    scoring=score_custom_regression)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----neural network pipe\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons=1):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=40, kernel_initializer='uniform', activation='linear', kernel_constraint=maxnorm(4)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='relu'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "# create model\n",
    "nnet = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "pipe=ImbPipe([\n",
    "            ('ft', FunctionTransformer(transform_features,validate=False)),\n",
    "            ('rs', StandardScaler()), \n",
    "            ('nnet',nnet)\n",
    "])\n",
    "\n",
    "# define the grid search parameters\n",
    "params = dict(neurons=[1,2,5])\n",
    "\n",
    "#grid3 = GridSearchCV(estimator=pipe,refit=True,param_grid=params,n_jobs=16,verbose=0,\n",
    "                    cv=TimeSeriesSplit(n_splits=2),\n",
    "                    scoring=\"log_loss\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
